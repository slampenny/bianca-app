name: Deploy to Staging

on:
  push:
    branches:
      - staging
  workflow_dispatch: # Allow manual triggers

env:
  AWS_REGION: us-east-2
  ECR_REGISTRY: 730335291008.dkr.ecr.us-east-2.amazonaws.com

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write  # Required for OIDC
      actions: read  # Required to checkout other repos
    
    steps:
      - name: Checkout backend code
        uses: actions/checkout@v4
        with:
          path: backend

      - name: Checkout frontend code
        uses: actions/checkout@v4
        with:
          repository: slampenny/bianca-app-frontend
          ref: staging  # Use staging branch for staging deployments
          path: frontend
          token: ${{ secrets.FRONTEND_REPO_TOKEN || secrets.GITHUB_TOKEN }}
        continue-on-error: true
        id: checkout-frontend
        # Note: Uses FRONTEND_REPO_TOKEN if available, otherwise GITHUB_TOKEN

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}
          role-session-name: GitHubActions-Staging-Deploy

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build and push images in parallel
        run: |
          # Build all images in parallel using background jobs
          echo "ğŸ”¨ Building images in parallel..."
          
          cd backend
          docker build -t ${{ env.ECR_REGISTRY }}/bianca-app-backend:staging . &
          BACKEND_PID=$!
          
          # Only build frontend if checkout succeeded
          if [ "${{ steps.checkout-frontend.outcome }}" == "success" ] && [ -d "../frontend" ]; then
            cd ../frontend
            docker build -t ${{ env.ECR_REGISTRY }}/bianca-app-frontend:staging \
              -f devops/Dockerfile --build-arg BUILD_ENV=staging . &
            FRONTEND_PID=$!
            BUILD_FRONTEND=true
          else
            echo "âš ï¸  Frontend checkout failed or not available, skipping frontend build"
            BUILD_FRONTEND=false
          fi
          
          cd ../backend/devops/asterisk
          docker build -t ${{ env.ECR_REGISTRY }}/bianca-app-asterisk:staging . &
          ASTERISK_PID=$!
          
          # Wait for all builds
          wait $BACKEND_PID && echo "âœ… Backend build complete" || exit 1
          if [ "$BUILD_FRONTEND" = true ]; then
            wait $FRONTEND_PID && echo "âœ… Frontend build complete" || exit 1
          fi
          wait $ASTERISK_PID && echo "âœ… Asterisk build complete" || exit 1
          
          # Push all images in parallel
          echo "ğŸ“¦ Pushing images to ECR in parallel..."
          docker push ${{ env.ECR_REGISTRY }}/bianca-app-backend:staging &
          if [ "$BUILD_FRONTEND" = true ]; then
            docker push ${{ env.ECR_REGISTRY }}/bianca-app-frontend:staging &
          fi
          docker push ${{ env.ECR_REGISTRY }}/bianca-app-asterisk:staging &
          
          wait
          echo "âœ… All images pushed successfully!"

      - name: Install Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.5.0"

      - name: Deploy infrastructure (if changed)
        working-directory: backend/devops/terraform
        run: |
          terraform init
          
          echo "ğŸ“‹ Running terraform plan..."
          set +e  # Don't exit on error immediately
          PLAN_OUTPUT=$(terraform plan -no-color -input=false 2>&1)
          PLAN_EXIT=$?
          echo "$PLAN_OUTPUT"
          set -e  # Re-enable exit on error
          
          if [ $PLAN_EXIT -ne 0 ]; then
            echo "âŒ Terraform plan failed with exit code $PLAN_EXIT"
            echo "This might be due to missing permissions or configuration issues."
            echo "Skipping Terraform apply for now - infrastructure may need manual attention."
            # Don't fail the entire workflow - containers can still be updated
            exit 0
          elif echo "$PLAN_OUTPUT" | grep -q "No changes"; then
            echo "âœ… No infrastructure changes detected. Skipping Terraform apply."
          else
            echo "ğŸ“‹ Infrastructure changes detected. Applying..."
            terraform apply -auto-approve -no-color
            echo "âœ… Terraform apply completed"
          fi

      - name: Setup SSH key
        run: |
          # Store SSH private key from GitHub Secrets
          echo "${{ secrets.STAGING_SSH_PRIVATE_KEY }}" > /tmp/staging-key.pem
          chmod 600 /tmp/staging-key.pem
          echo "âœ… SSH key configured"

      - name: Update staging containers
        run: |
          # Get staging instance ID (check for running instances first)
          INSTANCE_ID=$(aws ec2 describe-instances \
            --filters "Name=tag:Name,Values=bianca-staging" "Name=instance-state-name,Values=running" \
            --query 'Reservations[0].Instances[0].InstanceId' \
            --output text --region ${{ env.AWS_REGION }})
          
          if [ -z "$INSTANCE_ID" ] || [ "$INSTANCE_ID" == "None" ]; then
            echo "âš ï¸  Staging instance not running. Checking if it exists..."
            INSTANCE_ID=$(aws ec2 describe-instances \
              --filters "Name=tag:Name,Values=bianca-staging" \
              --query 'Reservations[0].Instances[0].InstanceId' \
              --output text --region ${{ env.AWS_REGION }})
            
            if [ -z "$INSTANCE_ID" ] || [ "$INSTANCE_ID" == "None" ]; then
              echo "âŒ Staging instance not found"
              exit 1
            fi
            
            echo "ğŸ”„ Starting stopped instance..."
            aws ec2 start-instances --instance-ids "$INSTANCE_ID" --region ${{ env.AWS_REGION }}
            echo "â³ Waiting for instance to start..."
            aws ec2 wait instance-running --instance-ids "$INSTANCE_ID" --region ${{ env.AWS_REGION }}
            echo "âœ… Instance started"
            sleep 10  # Give instance time to initialize
          fi
          
          echo "ğŸ“¡ Updating containers on instance: $INSTANCE_ID"
          
          # Get instance public IP for SSH
          echo "â³ Getting instance public IP..."
          INSTANCE_IP=$(aws ec2 describe-instances \
            --instance-ids "$INSTANCE_ID" \
            --region ${{ env.AWS_REGION }} \
            --query 'Reservations[0].Instances[0].PublicIpAddress' \
            --output text)
          
          if [ -z "$INSTANCE_IP" ] || [ "$INSTANCE_IP" == "None" ]; then
            echo "âŒ Could not get instance public IP"
            exit 1
          fi
          
          echo "ğŸ“¡ Connecting to instance: $INSTANCE_IP"
          
          # Wait for SSH to be ready (up to 60 seconds)
          echo "â³ Waiting for SSH to be ready..."
          for i in {1..12}; do
            if ssh -o StrictHostKeyChecking=no -o ConnectTimeout=5 -i /tmp/staging-key.pem ec2-user@$INSTANCE_IP "echo 'SSH ready'" 2>/dev/null; then
              echo "âœ… SSH is ready"
              break
            fi
            if [ $i -eq 12 ]; then
              echo "âš ï¸  SSH not ready after 60 seconds, proceeding anyway..."
            else
              echo "   Waiting for SSH... ($i/12)"
              sleep 5
            fi
          done
          
          # Use SSH to update containers (simpler than SSM, no IAM permission issues)
          ssh -o StrictHostKeyChecking=no -i /tmp/staging-key.pem ec2-user@$INSTANCE_IP bash -c "
            set -e
            cd /opt/bianca-staging &&
            echo 'ğŸ“¦ Logging into ECR...' &&
            ECR_TOKEN_FILE=/tmp/ecr-token-\$(date +%Y%m%d) &&
            if [ ! -f \"\$ECR_TOKEN_FILE\" ]; then
              aws ecr get-login-password --region us-east-2 | docker login --username AWS --password-stdin 730335291008.dkr.ecr.us-east-2.amazonaws.com &&
              touch \"\$ECR_TOKEN_FILE\"
            else
              echo '   Using cached ECR token'
            fi &&
            echo 'ğŸ“¥ Pulling latest images (forcing pull)...' &&
            docker-compose pull 2>&1 | tee /tmp/pull-output.log &&
            echo '' &&
            echo 'ğŸ“Š Pull summary:' &&
            grep -E 'Pulling|Downloaded|Image is up to date|Digest|Status' /tmp/pull-output.log | tail -10 || true &&
            rm -f /tmp/pull-output.log &&
            echo '' &&
            echo 'ğŸ”„ Stopping and removing old containers...' &&
            docker-compose down 2>/dev/null || true &&
            echo 'ğŸš€ Starting containers with new images...' &&
            docker-compose up -d --remove-orphans &&
            echo 'â³ Waiting for containers to start...' &&
            sleep 5 &&
            echo 'ğŸ“‹ Container status:' &&
            docker ps --format 'table {{.Names}}\t{{.Image}}\t{{.Status}}' | grep staging_ || true &&
            echo '' &&
            echo 'ğŸ” Checking image versions:' &&
            docker images --format 'table {{.Repository}}\t{{.Tag}}\t{{.CreatedAt}}' | grep 'bianca-app\|ECR' | head -5 || true
          "
          
          # SSH command executes synchronously, so if we get here, it succeeded
          if [ $? -eq 0 ]; then
            echo "âœ… Deployment completed successfully!"
          else
            echo "âŒ Deployment failed"
            exit 1
          fi

